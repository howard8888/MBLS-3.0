
'''
Meaningful-Based Cognitive Architecture
Nanosimulation of Microsimulation of Minisimulation of Full Simulation of MBCA
Simulation to focus on subsymbolic vs symbolic data streams

Python 3.6; Compatible with GPU CUDA usage for PyTorch
Verified for use with Google Colab Jupyter Notebook GPUs

"nano" simulation version:
PURPOSE: Provide a scaffolding, ie, a simulation via Python functions of the
         full MBCA, so that more authentic components can be dropped into
         "micro" and other finer-grain simulations of the MBCA


#  Table of Contents
#  -----------------
#  0.  Preface: Version and Technical Notes
#->1.  Introduction: Why Create this Program? <-
#  2.  Sleep/Wake and Autonomic Functions
#  3.  Lower-Level Assist Functions
#      2a. Main Module Lower-Level Assist Functions
#      2b. Imported Module
#  3A. Higher-Level Assist Functions
#  4.  High-Level MBLS Architecture Visible Functions
#      3a. Main Module High-Level MBLS Architecture Visible Functions
#      3b. Imported Module
#  5.  Main Program Code
#  6.  Embedded Software/Hardware Management
#
#

#1. INTRODUCTION: Why Create this Program?
#
#Introduction
#------------
At the time of this writing, despite the human-like performance of artificial neural networks
(ANNs) in sensory processing and reinforcement learning (Goodfellow, Bengio and Courville,
2016; Mnih, Kavukcuoglu, Silver, et al., 2015), such neural networks, trained with a very
small quantity of examples, cannot causally make sense of their environment or information
at the level a four-year old child can (Gopnik, Glymour, Sobel et al., 2004; Waismeyer,
Meltzoff, and Gopnik, 2015).  Recent successful work by Graves, Wayne, Reynolds and colleagues
(2016) helps to narrow the neural-symbolic gap. Their model involves an ANN which can read
and write to an external memory, i.e., a hybrid system. However, like the human brain, the
meaningful-based learning system (MBLS), introduced below, can perform the sensory
processing associated with ANNs and the efficient symbolic logic associated with human
cognition, without the use of an external memory, i.e., it is not a physically hybrid system.

Abstract from:
	2018 Annual International Conference on Biologically Inspired Cognitive Architectures
	Meaningful-Based Cognitive Architecture by Howard Schneider:

"An overview is given of the cognitive architecture of the biologically inspired
meaningful-based learning system (MBLS). The basic element of the MBLS is a reconfigurable
Hopfield-like network (HLN) which can rapidly connect to other HLNs depending on the level
of abstraction which yields a practical maximal “meaningfulness,” defined as the reciprocal
of the Shannon entropy of the HLNs. Without any external memory the MBLS synergistically
processes external data (and internal data – “thoughts”) with sensory processing abilities
found in neural networks and some of the symbolic logical abilities found in human cognition.
In practical applications the MBLS offers near-simultaneous pattern recognition and
comprehension. In modeling the development of psychotic disorders in humans, the MBLS
predicts that in many patients the etiology stems from the fragility of the working memory
and the integration of additional reasoning mechanisms during adolescence."
#
#Suggested References (last update: Sept 2018)
#---------------------------------------------

#pylint: disable=line-too-long
#justification: non-code area, not worth reformatting

[1]   Goodfellow, I., Bengio, Y. and Courville, A. Deep Learning. Cambridge, MA: MIT Press; 2016.
[2]   Mnih, V., Kavukcuoglu, K., Silver, D. … Hassabis, D. Human-level control through deep reinforcement learning. Nature Feb 26;518(7540):529-33; 2015.
[3]   Gopnik, A., Glymour, C., Sobel, D.M. et al. A Theory of Causal Learning in Children. Psychol Rev 111(1), 3-32; 2004.
[4]   Waismeyer, A., Meltzoff, A.N. and Gopnik, A. Causal learning from probabilistic events in 24-month-olds: an action measure. Developmental Science 18:1, pp175-182; 2015.
[5]   Graves, A., Wayne, G., Reynolds, M., … Hassabis, D.  Hybrid computing using a neural network with dynamic external memory. Nature 538, pp 471-476; 2016.
[6]   Lyke, J.C., Christodoulou, C.G., et al. An introduction to reconfigurable systems. Proc of the IEEE 103(3) 291-317; 2015.
[7]   Rojas, R. The Hopfield Model. In Neural Networks – A Systematic Introduction. New York, NY: Springer-Verlag; 1996.
[8]   Maurer, A., Hersch, M. and Billard, A.G. Extended Hopfield Network for Sequence Learning: Application to Gesture Recognition. Proceedings of the 15th International Conference on Artificial Neural Networks (ICANN), pp. 493- 498; 2005.
[9]   Laird, J.E., Lebiere, C. and Rosenbloom, P.S.  A Standard Model of the Mind: Toward a Common Computational Framework across Artificial Intelligence, Cognitive Science, Neuroscience and Robotics. AI Magazine 38(4); 2017.
[10]  Anderson, J.R., Bothell, D., Byrne, M.D., et al. An Integrated Theory of Mind. Psychol. Rev. 111(4),1036-1060; 2004.
[11]  Lázaro-Gredilla, M., Liu, Y., Phoenix, D.S., and George, D.  Hierarchical compositional feature learning. arXiv preprint arXiv:1611.02252v2; 2017.
[12]  Hawkins, J. and Blakeslee, S.  On Intelligence. New York, NY: Times Books; 2004.
[13]  Kurzweil, R.  How to Create a Mind.  New York, NY: Viking Press; 2012.
[14]  Sabour, S., Frosst, N. and Hinton, G.E.  Dynamic Routing Between Capsules. arXiv preprint arXiv:1710.09829v2; 2017.
[15]  Bastos, A.M., Usrey, W.M., Adams, R.A., et al.  Canonical Microcircuits for Predictive Coding. Neuron 76:695- 711; 2012.
[16]  Schneider, H.  Non-Hybrid Meaningful-Based Learning System Using a Configurable Network of Neural Networks. Proceedings of the 2018 International Conference on Artificial Intelligence  pp 96-102; Aug 2018.
[17]  Mountcastle, V.B. The columnar organization of the neocortex. Brain Apr: 120 (Pt 4):701-22; 1997.
[18]  Buxhoeveden, D.P. and Casanova, M.F. The minicolumn hypothesis in neuroscience. Brain May:125 (Pt 5):935-51; 2002.
[19]  Varela, F.J.  The Specious Present: A Neurophenomenology of Time Consciousness. In: Naturalizing Phenomenology – Jean, Petitot, et al., editors. Chap. 9, pp. 266- 329. Stanford, CA: Stanford University Press; 2000.
[20]  Schwalger, T., Deger, M. and Gerstner, W.  Towards a theory of cortical columns. PLoS Comput. Biol. 13(4); 2017.
[21]  Eliasmith,C. and Trujillo,O.  The use and abuse of large-scale brain models. Curr Opin Neurobiology. Apr; 25:1-6; 2014.
[22]  Cohen, J.D. and Servan-Schreiber, D.  Context, Cortex and Dopamine: A Connectionist Approach to Behavior and Biology in Schizophrenia. Psychological Review 99(1):45-77; 1992.
[23]  Papanastasiou, E., Mouchlianitis, E., Joyce, D.W., et al. Examination of the Neural Basis of Psychoticlike Experiences in Adolescence During Reward Processing. JAMA Psychiatry. Aug 1, doi:10.1001/jamapsychiatry.2018.1973; 2018.
[24]  Muraven,M. and Baumeister,R.F.  Self-regulation and depletion of limited resources. Psychol. Bull. 126(2):247-59; 2000.
[25]  van Os, J., Hanssen, M., Bijil, R.V. et al.  Prevalence of psychotic disorder and community level psychotic symptoms: an urban-rural comparison. Arch. Gen. Psychiatry Jul;58(7):663-8; 2001.
[26]  Jones, C.A., Watson, D.J.G. and Fone, K.C.F.  Animal models of schizophrenia. British Journal of Pharmacology 164:1162-1194; 2011.
[27]  Zhang, R., Pichhioni, M., Allen, P et al. Working Memory in Unaffected Relatives of Patients with Schizophrenia: A Meta-Analysis of Functional Magnetic Resonance Imaging Studies. Schizophrenia Bulletin 42(4): 1068-1077, 2016.
[28]  Bechdolf, A., Wagner, M., Ruhrmann, S. et al.  Preventing progression to first-episode psychosis in early initial prodromal states. British Journal of Psychiatry Jan; 200(1):22-9; 2012.
[29]  Fisher, M., Loewy, R., Hardy, K. et al.  Cognitive interventions targeting brain plasticity in the prodromal and early phases of schizophrenia. Annu Rev Clin Psychol. 9:435-63; 2013.
[30]  Sommer, I.E., Bearden, C.E., van Dellen, E. et al.  Early interventions in risk groups for schizophrenia: what are we waiting for? npj Schizophrenia Mar 9; 2:16003; 2016.



####################

#
#  Table of Contents
#  -----------------
#  0.  Preface: Version and Technical Notes
#  1.  Introduction: Why Create this Program?
#->2.  Sleep/Wake and Autonomic Functions <-
#  3.  Lower-Level Assist Functions
#      2a. Main Module Lower-Level Assist Functions
#      2b. Imported Module
#  3A. Higher-Level Assist Functions
#  4.  High-Level MBLS Architecture Visible Functions
#      3a. Main Module High-Level MBLS Architecture Visible Functions
#      3b. Imported Module
#  5.  Main Program Code
#  6.  Embedded Software/Hardware Management
#
#2. SLEEP/WAKE AND AUTONOMIC FUNCTIONS

#The sleep/wake and autonomic functions are inspired by the analogous biological functions,
#but their purpose is not to mimic nature but provide a useful level of very high overall
#control of the MBLS with regard to the sleep/wake functions, and to provide
#"stimulus->action"=="reflex" == "reptilian-like neurological functioning" ie, no cortical-like
#functioning but more of stimulus-action functioning although the strong caveat is made
#here that reptiles and birds and have cortical-like portions of their pallium and the
#stimulus->action effect is actually much more involved and processed than say stimulus->action
#in a worm. Thus, really the autonomic functions should be thought of as providing
#invertebrate-like stimulus->action processing, or if the case of mammals is considered,
#basic reflexes and basic autonomic processing.
#
#
#This section will be divided in future as number of functions grow into separate sleep/wake
#section, separate reflex autonomic function section (useful for very fast decisions)
#and more processed autonomic function section.
#
#
#3. LOWER-LEVEL ASSIST FUNCTIONS

#The functions help other functions do their tasks
#(further below are the MBLS Architecture functions)
#Lower-level assist functions do one or a few lower-level tasks,
#while the higher-level assist functions do more of function calling
#to prevent too much code in the main code section
#
#


#3A. HIGHER-LEVEL ASSIST FUNCTIONS

#(further below are the MBLS Architecture functions)
#Lower-level assist functions do one or a few lower-level tasks, while
#the higer-level assist functions do more of function calling to
#to prevent too much code in the main code section
#
#
#pylint: disable=line-too-long
#justification: old version 2 code
def start_simulation(message_x):

    if DEVELOPER_USER:
        #HOP NOTE: From 'Flags used for Development Purposes' at start of code
        print("System is running in Developer User Mode right now.")
        print('Version {} of "{}" was last modified {}.'.format(VERSION_NUMBER, VERSION_FILE_NAME, time.ctime(os.path.getmtime(VERSION_FILE_NAME))))
        print('Platform Info (warning: tend to get conflicting info from Python Standard Library routines -- verify if important): \n  ',
              '(note that conventional AMD and Intel CPUs are both functionally compatible with x86(_64) architecture) \n  ',
              'os.name:', os.name, '\n  ', 'sys.platform:', sys.platform, '\n  ', 'platform.system:', platform.system(), '\n  ',
              'platform.release:', platform.release(), '\n  ', 'platform.machine:', platform.machine(), '\n  ', 'platform.architecture:', platform.architecture(),
              '\n  ', 'platform.processor:', platform.processor(), '\n   sys.maxsize (9223372036854775807 for 64 bit Python): ', sys.maxsize,
              '\n   GPU resources: ', 'not determined at present')
        print("Verify no memory error from creating 10,000 x 10,000 Numpy matrix ....")
        print("Interim mod: 100 x 100 matrix for moment.... ")
        print(np.zeros((100, 100)))
        print("Ok.... basic infrastructure in place for program to run....")
        #set_debugging_level()
        print('\n')

    if not DEVELOPER_USER:
        #HOP NOTE: From 'Flags used for Development Purposes' at start of code
        print("Running in Normal User Mode (not Developer Mode)")

    mbll.welcome(message_x)
#pylint: enable=line-too-long

####################

#
#  Table of Contents
#  -----------------
#  0.  Preface: Version and Technical Notes
#  1.  Introduction: Why Create this Program?
#  2.  Sleep/Wake and Autonomic Functions <-
#  3.  Lower-Level Assist Functions
#      2a. Main Module Lower-Level Assist Functions
#      2b. Imported Module
#  3A. Higher-Level Assist Functions
#->4.  High-Level MBLS Architecture Visible Functions<-
#      3a. Main Module High-Level MBLS Architecture Visible Functions
#      3b. Imported Module
#  5.  Main Program Code
#  6.  Embedded Software/Hardware Management
#

#4. HIGH-LEVEL MBLS ARCHITECTURE VISIBLE FUNCTIONS

#Each of these functions corresponds to a high-level
#component of the MBLS Cognitive Architecture
#
#

	HLNs Autoconfigured as Logic/Working Memory1
	MBLS ARCHITECTURE VISIBLE COMPONENT
	At present just returns input
	#
	#
	[Much of the MBLS memory, as shown in Figure 4, is represented by HLNs auto-configured into networks of
causal memory, keeping track of which event follows another event, and what the interesting sensory data
were at the time. The intrinsic connections in the brain between hierarchical cortical columns may by
default establish Bayesian inference (Bastos, Usrey, Adams, et al., 2012), although it can informally
be shown that such connections would not be sufficient to easily allow the higher-level inferences
humans perform without groups of HLNs configured as working memory/logic units.  In a group of HLNs
auto-configured as a ‘working memory/logic unit’ (or ‘working memory’ for short) there can be logical
manipulation of the information held there.]
	The MBLS can be designed (via default weights) such that while some of the HLNs can auto-configure
with each other to form various sensory-processing hierarchies and various causal memory networks,
other parts of the MBLS can auto-configure to set up a group(s) of HLNs which will act as a working
memory with varying degrees of logical processing operating on the contents of this memory (in theory,
ranging from acting as small automatons to Church-Turing complete logical sub-systems). It is important
to realize that the representation of data in the MBLS is already quite causal and has meaning through
the connections an HLN has via connections to other HLNs. The working memory need not convert the
vectors from the HLN into some abstract symbolic data for the working memory to produce symbolic
behavior, i.e., manipulation of the HLN vectors it receives suffices. In the simulation of the MBLS,
described below, it can be shown that HLNs auto-configured as relatively simple logic/working memory
units are able to compare properties of vectors they receive, are able to choose one vector over
another, are able to pattern match a vector from the entire MBLS memory, and are able to direct the
MBLS to output a vector.
	#
As noted above, the MBLS can be designed so that there are group(s) of HLNs which will act as a working memory
with varying degrees of logical processing operating on the contents of this memory. These groups of HLNs,
“logic/working memory units”, are able to compare properties of vectors they receive, are able to choose one
vector over another, are able to pattern match a vector from the entire MBLS memory, and are able to direct the
MBLS to output a vector. A typical MBLS cognitive architecture is shown in Figure 4 below. Every evaluation cycle,
not only does the MBLS look at the meaningfulness of the data in the sensory input and cycle through varying levels
of abstraction so as to reconfigure the HLNs in a way to maximize local and system meaningfulness (via a feedback
vector to all the HLNs), but the sensory input vector or the casual memory vector it triggers (or other vectors,
as shown in the architecture of Figure 4) also go to the logic/working memory unit. The logic at the time may be
to do nothing, or it may be, for example to compare this vector with another vector previously triggered, and if
enough of a match then trigger another vector, for example, into the logic/working memory unit, or perhaps as an
output vector, for example.
Thus every evaluation cycle, the MBLS looks at the meaningfulness of the data in the sensory input vectors (local
and system meaningfulness is fed back to the HLNs via the feedback vector to allow evaluation of meaningfulness),
and the results of any operations in the logic/working memory, i.e., essentially a symbolic logical operation on the
data. The evaluation cycle completes, connections within the auto-associative processors of the HLNs are strengthened
or weakened in relation to neural-level activity and the feedback vector, connections between HLNs are strengthened and
weakened in response to the feedback vector, and the next evaluation cycle starts again. The above occurs automatically,
over and over again.
	#
In an evaluation cycle, rather than evaluating an input vector from the sensory systems, the MBLS can instead
equally evaluate a data vector from the logic/working memory unit as the next input vector. Essentially a thought
occurs. The current data vector from the logic/working memory is treated as the next input vector, and fed back into
the logic/working memory unit while HLNs are reconfigured to maximize meaningfulness. The evaluation cycle completes,
synapses are (or are set to be) strengthened or weakened, and the next evaluation cycle starts again. In the next evaluation
cycle the newly processed data vector in the logic/working memory can again be considered as the next input vector to evaluate.
As such, thoughts can be processed sequentially in a fashion to extract maximum meaningfulness from them.
	#

Creativity in solving problems is possible for the MBLS via algorithms applied to the logic/working memory units, and also
intrinsically within the HLNs. The operation of the MBLS can be skewed so that alternative solutions emerge that would not normally
represent the extraction of the maximal meaningfulness from the input (or thoughts from the working memory subunits), by altering
the values of the external inputs so as to give more obscure aspects of the input data closer pattern matching and hence a higher
value of meaningfulness.

	
For use to compare the MBLS with other cognitive
    architectures and information systems.

    The MBLS architecture involves hierarchies of pattern recognizers
    (the HLNs) which gives it similarities but also different properties than deep learning
    systems (e.g., Lázaro-Gredilla et al., 2017; Goodfellow et al., 2016).  Work on hierarchies
    of pattern recognizers actually started many years ago with Mountcastle’s (1957) hypothesis
    concerning the columnar organization of the cerebral cortex, and continued strongly in the
    last two decades (e.g., George and Hawkins, 2009; Lázaro-Gredilla et al., 2017).
    The MBLS builds upon previous work in artificial neural networks and systems of
    hierarchies of pattern recognizers, but has a number of different learning mechanisms
    which can use common techniques from previous work (e.g., Hebbian-like learning and
    gradient descent-like algorithms within the HLNs and/or between the different HLNs)
    but also different ones too (e.g., discrete immediate strong connections between HLNs,
    only briefly touched upon above, e.g., extreme rapid reconfigurations of HLNs with each
    other depending on meaningfulness values). The MBLS has a number of different operational
    features than previous work, such as the extreme rapid reconfigurations it undergoes in
    an attempt to maximize meaningfulness. The MBLS has a number of different features in its
    architecture than previous work, such as for example, lack of sharp demarcation and structures
    for long-term procedural memory versus long-term declarative memory, but instead, it heavily
    relies on a long-term causal memory. As well, the MBLS incorporates from its elementary
    HLN units, without the aid of an external CPU or memory, regions that can symbolically process
    input vectors (as well as symbolically-processed data vectors fed back to itself as thoughts)
    in the context of the entire MBLS rather than independently as an external CPU would do.
    While recent works have started narrowing the neural-symbolic gap (e.g., Graves et al., 2016;
    Sabour et al., 2017), it is believed that the meaningful-based learning system (MBLS) can close
    it – the MBLS should be able to perform the sensory processing associated with artificial
    neural networks while retaining the efficiently learned causal symbolic processing of the
    human brain.
    

#
#  Table of Contents
#  -----------------
#  0.  Preface: Version and Technical Notes
#  1.  Introduction: Why Create this Program?
#  2.  Sleep/Wake and Autonomic Functions <-
#  3.  Lower-Level Assist Functions
#      2a. Main Module Lower-Level Assist Functions
#      2b. Imported Module
#  3A. Higher-Level Assist Functions
#  4.  High-Level MBLS Architecture Visible Functions
#      3a. Main Module High-Level MBLS Architecture Visible Functions
#      3b. Imported Module
#->5.  Main Program Code <-
#  6.  Embedded Software/Hardware Management
#

#5. MAIN PROGRAM CODE

#
#
#The above occurs automatically, over and over again. Every
#evaluation cycle, the MBLS looks at the meaningfulness of the
#data in the sensory input vectors with modulation by the external
#inputs, and cycles through varying levels of abstraction so as
#to reconfigure the HLNs in a way to maximize local and system
#meaningfulness, which also can include utilization of the HLNs
#connected to the HLNs forming the working memory subunits and logic
#subunits. The evaluation cycle completes, local and system meaningfulness
#is fed back to the HLNs via the feedback vector, and the next evaluation
#cycle starts again.


####################

#
#  Table of Contents
#  -----------------
#  0.  Preface: Version and Technical Notes
#  1.  Introduction: Why Create this Program?
#  2.  Sleep/Wake and Autonomic Functions <-
#  3.  Lower-Level Assist Functions
#      2a. Main Module Lower-Level Assist Functions
#      2b. Imported Module
#  3A. Higher-Level Assist Functions
#  4.  High-Level MBLS Architecture Visible Functions
#      3a. Main Module High-Level MBLS Architecture Visible Functions
#      3b. Imported Module
#  5.  Main Program Code
#->6.  Embedded Software/Hardware Management <-
#      6a. MicroPython Implementation and Communication
#

#6. EMBEDDED SOFTWARE/HARDWARE MANAGEMENT

#Goal of MBLS-3.0 Implementation is to use the Meaningful-Based Cognitive Architecture to
#control a Search-and-Rescue Robot, with the simulation of finding a lost hiker in a forest
#filled with a host of sensory noise and other irrelevant sensory signals.
#
#
#Many of the key embedded and multi-threading functions for this purpose are at this time
#implemented as inner functions encapsulated away from the non-embedded MBLS code.
#
#

#
#  Table of Contents
#  -----------------
#  0.  Preface: Version and Technical Notes
#  1.  Introduction: Why Create this Program?
#  2.  Sleep/Wake and Autonomic Functions <-
#  3.  Lower-Level Assist Functions
#      2a. Main Module Lower-Level Assist Functions
#      2b. Imported Module
#  3A. Higher-Level Assist Functions
#  4.  High-Level MBLS Architecture Visible Functions
#      3a. Main Module High-Level MBLS Architecture Visible Functions
#      3b. Imported Module
#  5.  Main Program Code
#  6.  Embedded Software/Hardware Management <-
#->    6a. MicroPython Implementation and Communication
#
#6a. MicroPython Implementation and Communication
#------------------------------------------------
#justification: Some minimal documentation is required about direction of hardware interfacing.

The goal of the MBLS-3.0 Implementation is to use the Meaningful-Based Cognitive Architecture
to control a Search-and-Rescue Robot, with the simulation of finding a lost hiker in a forest
filled with a host of sensory noise and other irrelevant sensory signals. Thus, the code above
must be able to somehow interface with the electronics of such a Search-and-Rescue Robot. This
issue has not been resolved at the time of this writing.

If a completely self-contained Search-and-Rescue Robot exists with some sort of interface to
high level instructions and data, then the issue becomes more of a digital communication issue
bidirectionally (the MBLS requires data in as well, not just instructions out) between the
MBLS code above and the Robot. More likely there will be the need to interface at a lower level
to the electronic circuitry of the Robot. In either case, there is the need of physical
communication between the above MBLS code and the Robot. 

At this time, the use of a MicroPython board (or multiple MicroPython boards) is considered as
the approach to the issue of communication, and would be able to handle a wide spectrum of
requirements from abstracted to detailed communication requirements between the main code and
the Robot hardware implementation.

MicroPython is an implementation of Python3 optimized to run on a compatible
micro-controller board. MicroPython is a subset of the full Python 3 and its Standard Library.
As such the above MBLS code has to be refactored so that necessary parts dealing with the
hardware implementation can run in the MicroPython environment. At the time of
this writing, MicroPython requires 256K of code space and 16K of RAM.

Note: MicroPython is an open source software under the MIT license which at this time has over
two hundred contributors.

Note: Although in theory MicroPython can run on a variety of micro-controller boards, in practice
a 'PyBoard' or equivalent (eg, WiPy IoT platform) should be used since the PyBoard has been
designed to run MicroPython code. PyBoards are not as readily available as other micro-controller
boards, eg, Arduino's, but can be commercially purchased from several sources at time of writing.


def embedded_main_pyboard():
While run different portions of the MBLS in multiple threads for
    use with an embedded version of the MBLS-3.0 in, for example, a Search-and-
    Rescue Robot.
    MicroPython compiled bytecode
    PyTorch nor any Jupyter Notebook related routines cannot be run and must
     be swapped for routines capable running on the board.
    DEPRECATION NOTE: "nano", "micro", "mini", "full" code has not been
     evaluated in the MicroPython environment;
     todo -- re-evaluate granular simulations in MicroPython envrt and
       contemporary PyBoard hardware
     todo -- physical Wumpus World implementation

    